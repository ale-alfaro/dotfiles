<html class="_theme-default">
<head>
    <meta charset="utf-8">
    <title>3.18.58. x86 Options</title>
    
    <link rel="preload" href="assets/index.js" as="script" type="text/javascript" />

    <link rel="stylesheet" type="text/css" href="application.css" />
    <link rel="stylesheet" type="text/css" href="assets/index.css" />
</head>
<body>
    <div class="_app">
        <devdocs-navbar current="x86-options" prefix="" listing-src="navbar.json"></devdocs-navbar>
        <div class="_container">
            <main class="_content">
                <div class="_page _gcc"><h1 class="subsection" id="x86-Options-1">3.18.58 x86 Options</h1>  <p id="index-x86-Options">These ‘<samp>-m</samp>’ options are defined for the x86 family of computers. </p> <dl compact> <dt><code>-march=<var>cpu-type</var></code></dt> <dd> <p id="index-march-14">Generate instructions for the machine type <var>cpu-type</var>. In contrast to <samp>-mtune=<var>cpu-type</var></samp>, which merely tunes the generated code for the specified <var>cpu-type</var>, <samp>-march=<var>cpu-type</var></samp> allows GCC to generate code that may not run at all on processors other than the one indicated. Specifying <samp>-march=<var>cpu-type</var></samp> implies <samp>-mtune=<var>cpu-type</var></samp>. </p> <p>The choices for <var>cpu-type</var> are: </p> <dl compact> <dt>‘<samp>native</samp>’</dt> <dd>
<p>This selects the CPU to generate code for at compilation time by determining the processor type of the compiling machine. Using <samp>-march=native</samp> enables all instruction subsets supported by the local machine (hence the result might not run on different machines). Using <samp>-mtune=native</samp> produces code optimized for the local machine under the constraints of the selected instruction set. </p> </dd> <dt>‘<samp>x86-64</samp>’</dt> <dd>
<p>A generic CPU with 64-bit extensions. </p> </dd> <dt>‘<samp>i386</samp>’</dt> <dd>
<p>Original Intel i386 CPU. </p> </dd> <dt>‘<samp>i486</samp>’</dt> <dd>
<p>Intel i486 CPU. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>i586</samp>’</dt> <dt>‘<samp>pentium</samp>’</dt> <dd>
<p>Intel Pentium CPU with no MMX support. </p> </dd> <dt>‘<samp>lakemont</samp>’</dt> <dd>
<p>Intel Lakemont MCU, based on Intel Pentium CPU. </p> </dd> <dt>‘<samp>pentium-mmx</samp>’</dt> <dd>
<p>Intel Pentium MMX CPU, based on Pentium core with MMX instruction set support. </p> </dd> <dt>‘<samp>pentiumpro</samp>’</dt> <dd>
<p>Intel Pentium Pro CPU. </p> </dd> <dt>‘<samp>i686</samp>’</dt> <dd>
<p>When used with <samp>-march</samp>, the Pentium Pro instruction set is used, so the code runs on all i686 family chips. When used with <samp>-mtune</samp>, it has the same meaning as ‘<samp>generic</samp>’. </p> </dd> <dt>‘<samp>pentium2</samp>’</dt> <dd>
<p>Intel Pentium II CPU, based on Pentium Pro core with MMX instruction set support. </p> </dd> <dt>‘<samp>pentium3</samp>’</dt> <dt>‘<samp>pentium3m</samp>’</dt> <dd>
<p>Intel Pentium III CPU, based on Pentium Pro core with MMX and SSE instruction set support. </p> </dd> <dt>‘<samp>pentium-m</samp>’</dt> <dd>
<p>Intel Pentium M; low-power version of Intel Pentium III CPU with MMX, SSE and SSE2 instruction set support. Used by Centrino notebooks. </p> </dd> <dt>‘<samp>pentium4</samp>’</dt> <dt>‘<samp>pentium4m</samp>’</dt> <dd>
<p>Intel Pentium 4 CPU with MMX, SSE and SSE2 instruction set support. </p> </dd> <dt>‘<samp>prescott</samp>’</dt> <dd>
<p>Improved version of Intel Pentium 4 CPU with MMX, SSE, SSE2 and SSE3 instruction set support. </p> </dd> <dt>‘<samp>nocona</samp>’</dt> <dd>
<p>Improved version of Intel Pentium 4 CPU with 64-bit extensions, MMX, SSE, SSE2 and SSE3 instruction set support. </p> </dd> <dt>‘<samp>core2</samp>’</dt> <dd>
<p>Intel Core 2 CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3 and SSSE3 instruction set support. </p> </dd> <dt>‘<samp>nehalem</samp>’</dt> <dd>
<p>Intel Nehalem CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2 and POPCNT instruction set support. </p> </dd> <dt>‘<samp>westmere</samp>’</dt> <dd>
<p>Intel Westmere CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AES and PCLMUL instruction set support. </p> </dd> <dt>‘<samp>sandybridge</samp>’</dt> <dd>
<p>Intel Sandy Bridge CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AES and PCLMUL instruction set support. </p> </dd> <dt>‘<samp>ivybridge</samp>’</dt> <dd>
<p>Intel Ivy Bridge CPU with 64-bit extensions, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AES, PCLMUL, FSGSBASE, RDRND and F16C instruction set support. </p> </dd> <dt>‘<samp>haswell</samp>’</dt> <dd>
<p>Intel Haswell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2 and F16C instruction set support. </p> </dd> <dt>‘<samp>broadwell</samp>’</dt> <dd>
<p>Intel Broadwell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED ADCX and PREFETCHW instruction set support. </p> </dd> <dt>‘<samp>skylake</samp>’</dt> <dd>
<p>Intel Skylake CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC and XSAVES instruction set support. </p> </dd> <dt>‘<samp>bonnell</samp>’</dt> <dd>
<p>Intel Bonnell CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3 and SSSE3 instruction set support. </p> </dd> <dt>‘<samp>silvermont</samp>’</dt> <dd>
<p>Intel Silvermont CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AES, PREFETCHW, PCLMUL and RDRND instruction set support. </p> </dd> <dt>‘<samp>goldmont</samp>’</dt> <dd>
<p>Intel Goldmont CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AES, PREFETCHW, PCLMUL, RDRND, XSAVE, XSAVEC, XSAVES, XSAVEOPT and FSGSBASE instruction set support. </p> </dd> <dt>‘<samp>goldmont-plus</samp>’</dt> <dd>
<p>Intel Goldmont Plus CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AES, PREFETCHW, PCLMUL, RDRND, XSAVE, XSAVEC, XSAVES, XSAVEOPT, FSGSBASE, PTWRITE, RDPID, SGX and UMIP instruction set support. </p> </dd> <dt>‘<samp>tremont</samp>’</dt> <dd>
<p>Intel Tremont CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AES, PREFETCHW, PCLMUL, RDRND, XSAVE, XSAVEC, XSAVES, XSAVEOPT, FSGSBASE, PTWRITE, RDPID, SGX, UMIP, GFNI-SSE, CLWB, MOVDIRI, MOVDIR64B, CLDEMOTE and WAITPKG instruction set support. </p> </dd> <dt>‘<samp>knl</samp>’</dt> <dd>
<p>Intel Knight’s Landing CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, PREFETCHWT1, AVX512F, AVX512PF, AVX512ER and AVX512CD instruction set support. </p> </dd> <dt>‘<samp>knm</samp>’</dt> <dd>
<p>Intel Knights Mill CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, PREFETCHWT1, AVX512F, AVX512PF, AVX512ER, AVX512CD, AVX5124VNNIW, AVX5124FMAPS and AVX512VPOPCNTDQ instruction set support. </p> </dd> <dt>‘<samp>skylake-avx512</samp>’</dt> <dd>
<p>Intel Skylake Server CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, CLWB, AVX512VL, AVX512BW, AVX512DQ and AVX512CD instruction set support. </p> </dd> <dt>‘<samp>cannonlake</samp>’</dt> <dd>
<p>Intel Cannonlake Server CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, AVX512VL, AVX512BW, AVX512DQ, AVX512CD, AVX512VBMI, AVX512IFMA, SHA and UMIP instruction set support. </p> </dd> <dt>‘<samp>icelake-client</samp>’</dt> <dd>
<p>Intel Icelake Client CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, AVX512VL, AVX512BW, AVX512DQ, AVX512CD, AVX512VBMI, AVX512IFMA, SHA, CLWB, UMIP, RDPID, GFNI, AVX512VBMI2, AVX512VPOPCNTDQ, AVX512BITALG, AVX512VNNI, VPCLMULQDQ, VAES instruction set support. </p> </dd> <dt>‘<samp>icelake-server</samp>’</dt> <dd>
<p>Intel Icelake Server CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, AVX512VL, AVX512BW, AVX512DQ, AVX512CD, AVX512VBMI, AVX512IFMA, SHA, CLWB, UMIP, RDPID, GFNI, AVX512VBMI2, AVX512VPOPCNTDQ, AVX512BITALG, AVX512VNNI, VPCLMULQDQ, VAES, PCONFIG and WBNOINVD instruction set support. </p> </dd> <dt>‘<samp>cascadelake</samp>’</dt> <dd>
<p>Intel Cascadelake CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, CLWB, AVX512VL, AVX512BW, AVX512DQ, AVX512CD and AVX512VNNI instruction set support. </p> </dd> <dt>‘<samp>tigerlake</samp>’</dt> <dd>
<p>Intel Tigerlake CPU with 64-bit extensions, MOVBE, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, POPCNT, PKU, AVX, AVX2, AES, PCLMUL, FSGSBASE, RDRND, FMA, BMI, BMI2, F16C, RDSEED, ADCX, PREFETCHW, CLFLUSHOPT, XSAVEC, XSAVES, AVX512F, AVX512VL, AVX512BW, AVX512DQ, AVX512CD, AVX512VBMI, AVX512IFMA, SHA, CLWB, UMIP, RDPID, GFNI, AVX512VBMI2, AVX512VPOPCNTDQ, AVX512BITALG, AVX512VNNI, VPCLMULQDQ, VAES, PCONFIG, WBNOINVD, MOVDIRI, MOVDIR64B and CLWB instruction set support. </p> </dd> <dt>‘<samp>k6</samp>’</dt> <dd>
<p>AMD K6 CPU with MMX instruction set support. </p> </dd> <dt>‘<samp>k6-2</samp>’</dt> <dt>‘<samp>k6-3</samp>’</dt> <dd>
<p>Improved versions of AMD K6 CPU with MMX and 3DNow! instruction set support. </p> </dd> <dt>‘<samp>athlon</samp>’</dt> <dt>‘<samp>athlon-tbird</samp>’</dt> <dd>
<p>AMD Athlon CPU with MMX, 3dNOW!, enhanced 3DNow! and SSE prefetch instructions support. </p> </dd> <dt>‘<samp>athlon-4</samp>’</dt> <dt>‘<samp>athlon-xp</samp>’</dt> <dt>‘<samp>athlon-mp</samp>’</dt> <dd>
<p>Improved AMD Athlon CPU with MMX, 3DNow!, enhanced 3DNow! and full SSE instruction set support. </p> </dd> <dt>‘<samp>k8</samp>’</dt> <dt>‘<samp>opteron</samp>’</dt> <dt>‘<samp>athlon64</samp>’</dt> <dt>‘<samp>athlon-fx</samp>’</dt> <dd>
<p>Processors based on the AMD K8 core with x86-64 instruction set support, including the AMD Opteron, Athlon 64, and Athlon 64 FX processors. (This supersets MMX, SSE, SSE2, 3DNow!, enhanced 3DNow! and 64-bit instruction set extensions.) </p> </dd> <dt>‘<samp>k8-sse3</samp>’</dt> <dt>‘<samp>opteron-sse3</samp>’</dt> <dt>‘<samp>athlon64-sse3</samp>’</dt> <dd>
<p>Improved versions of AMD K8 cores with SSE3 instruction set support. </p> </dd> <dt>‘<samp>amdfam10</samp>’</dt> <dt>‘<samp>barcelona</samp>’</dt> <dd>
<p>CPUs based on AMD Family 10h cores with x86-64 instruction set support. (This supersets MMX, SSE, SSE2, SSE3, SSE4A, 3DNow!, enhanced 3DNow!, ABM and 64-bit instruction set extensions.) </p> </dd> <dt>‘<samp>bdver1</samp>’</dt> <dd><p>CPUs based on AMD Family 15h cores with x86-64 instruction set support. (This supersets FMA4, AVX, XOP, LWP, AES, PCL_MUL, CX16, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM and 64-bit instruction set extensions.) </p></dd> <dt>‘<samp>bdver2</samp>’</dt> <dd><p>AMD Family 15h core based CPUs with x86-64 instruction set support. (This supersets BMI, TBM, F16C, FMA, FMA4, AVX, XOP, LWP, AES, PCL_MUL, CX16, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM and 64-bit instruction set extensions.) </p></dd> <dt>‘<samp>bdver3</samp>’</dt> <dd><p>AMD Family 15h core based CPUs with x86-64 instruction set support. (This supersets BMI, TBM, F16C, FMA, FMA4, FSGSBASE, AVX, XOP, LWP, AES, PCL_MUL, CX16, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM and 64-bit instruction set extensions. </p></dd> <dt>‘<samp>bdver4</samp>’</dt> <dd>
<p>AMD Family 15h core based CPUs with x86-64 instruction set support. (This supersets BMI, BMI2, TBM, F16C, FMA, FMA4, FSGSBASE, AVX, AVX2, XOP, LWP, AES, PCL_MUL, CX16, MOVBE, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM and 64-bit instruction set extensions. </p> </dd> <dt>‘<samp>znver1</samp>’</dt> <dd><p>AMD Family 17h core based CPUs with x86-64 instruction set support. (This supersets BMI, BMI2, F16C, FMA, FSGSBASE, AVX, AVX2, ADCX, RDSEED, MWAITX, SHA, CLZERO, AES, PCL_MUL, CX16, MOVBE, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM, XSAVEC, XSAVES, CLFLUSHOPT, POPCNT, and 64-bit instruction set extensions. </p></dd> <dt>‘<samp>znver2</samp>’</dt> <dd>
<p>AMD Family 17h core based CPUs with x86-64 instruction set support. (This supersets BMI, BMI2, ,CLWB, F16C, FMA, FSGSBASE, AVX, AVX2, ADCX, RDSEED, MWAITX, SHA, CLZERO, AES, PCL_MUL, CX16, MOVBE, MMX, SSE, SSE2, SSE3, SSE4A, SSSE3, SSE4.1, SSE4.2, ABM, XSAVEC, XSAVES, CLFLUSHOPT, POPCNT, and 64-bit instruction set extensions.) </p> </dd> <dt>‘<samp>btver1</samp>’</dt> <dd>
<p>CPUs based on AMD Family 14h cores with x86-64 instruction set support. (This supersets MMX, SSE, SSE2, SSE3, SSSE3, SSE4A, CX16, ABM and 64-bit instruction set extensions.) </p> </dd> <dt>‘<samp>btver2</samp>’</dt> <dd>
<p>CPUs based on AMD Family 16h cores with x86-64 instruction set support. This includes MOVBE, F16C, BMI, AVX, PCL_MUL, AES, SSE4.2, SSE4.1, CX16, ABM, SSE4A, SSSE3, SSE3, SSE2, SSE, MMX and 64-bit instruction set extensions. </p> </dd> <dt>‘<samp>winchip-c6</samp>’</dt> <dd>
<p>IDT WinChip C6 CPU, dealt in same way as i486 with additional MMX instruction set support. </p> </dd> <dt>‘<samp>winchip2</samp>’</dt> <dd>
<p>IDT WinChip 2 CPU, dealt in same way as i486 with additional MMX and 3DNow! instruction set support. </p> </dd> <dt>‘<samp>c3</samp>’</dt> <dd>
<p>VIA C3 CPU with MMX and 3DNow! instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>c3-2</samp>’</dt> <dd>
<p>VIA C3-2 (Nehemiah/C5XL) CPU with MMX and SSE instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>c7</samp>’</dt> <dd>
<p>VIA C7 (Esther) CPU with MMX, SSE, SSE2 and SSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>samuel-2</samp>’</dt> <dd>
<p>VIA Eden Samuel 2 CPU with MMX and 3DNow! instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nehemiah</samp>’</dt> <dd>
<p>VIA Eden Nehemiah CPU with MMX and SSE instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>esther</samp>’</dt> <dd>
<p>VIA Eden Esther CPU with MMX, SSE, SSE2 and SSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>eden-x2</samp>’</dt> <dd>
<p>VIA Eden X2 CPU with x86-64, MMX, SSE, SSE2 and SSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>eden-x4</samp>’</dt> <dd>
<p>VIA Eden X4 CPU with x86-64, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX and AVX2 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano</samp>’</dt> <dd>
<p>Generic VIA Nano CPU with x86-64, MMX, SSE, SSE2, SSE3 and SSSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano-1000</samp>’</dt> <dd>
<p>VIA Nano 1xxx CPU with x86-64, MMX, SSE, SSE2, SSE3 and SSSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano-2000</samp>’</dt> <dd>
<p>VIA Nano 2xxx CPU with x86-64, MMX, SSE, SSE2, SSE3 and SSSE3 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano-3000</samp>’</dt> <dd>
<p>VIA Nano 3xxx CPU with x86-64, MMX, SSE, SSE2, SSE3, SSSE3 and SSE4.1 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano-x2</samp>’</dt> <dd>
<p>VIA Nano Dual Core CPU with x86-64, MMX, SSE, SSE2, SSE3, SSSE3 and SSE4.1 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>nano-x4</samp>’</dt> <dd>
<p>VIA Nano Quad Core CPU with x86-64, MMX, SSE, SSE2, SSE3, SSSE3 and SSE4.1 instruction set support. (No scheduling is implemented for this chip.) </p> </dd> <dt>‘<samp>geode</samp>’</dt> <dd><p>AMD Geode embedded processor with MMX and 3DNow! instruction set support. </p></dd> </dl> </dd> <dt><code>-mtune=<var>cpu-type</var></code></dt> <dd> <p id="index-mtune-16">Tune to <var>cpu-type</var> everything applicable about the generated code, except for the ABI and the set of available instructions. While picking a specific <var>cpu-type</var> schedules things appropriately for that particular chip, the compiler does not generate any code that cannot run on the default machine type unless you use a <samp>-march=<var>cpu-type</var></samp> option. For example, if GCC is configured for i686-pc-linux-gnu then <samp>-mtune=pentium4</samp> generates code that is tuned for Pentium 4 but still runs on i686 machines. </p> <p>The choices for <var>cpu-type</var> are the same as for <samp>-march</samp>. In addition, <samp>-mtune</samp> supports 2 extra choices for <var>cpu-type</var>: </p> <dl compact> <dt>‘<samp>generic</samp>’</dt> <dd>
<p>Produce code optimized for the most common IA32/AMD64/EM64T processors. If you know the CPU on which your code will run, then you should use the corresponding <samp>-mtune</samp> or <samp>-march</samp> option instead of <samp>-mtune=generic</samp>. But, if you do not know exactly what CPU users of your application will have, then you should use this option. </p> <p>As new processors are deployed in the marketplace, the behavior of this option will change. Therefore, if you upgrade to a newer version of GCC, code generation controlled by this option will change to reflect the processors that are most common at the time that version of GCC is released. </p> <p>There is no <samp>-march=generic</samp> option because <samp>-march</samp> indicates the instruction set the compiler can use, and there is no generic instruction set applicable to all processors. In contrast, <samp>-mtune</samp> indicates the processor (or, in this case, collection of processors) for which the code is optimized. </p> </dd> <dt>‘<samp>intel</samp>’</dt> <dd>
<p>Produce code optimized for the most current Intel processors, which are Haswell and Silvermont for this version of GCC. If you know the CPU on which your code will run, then you should use the corresponding <samp>-mtune</samp> or <samp>-march</samp> option instead of <samp>-mtune=intel</samp>. But, if you want your application performs better on both Haswell and Silvermont, then you should use this option. </p> <p>As new Intel processors are deployed in the marketplace, the behavior of this option will change. Therefore, if you upgrade to a newer version of GCC, code generation controlled by this option will change to reflect the most current Intel processors at the time that version of GCC is released. </p> <p>There is no <samp>-march=intel</samp> option because <samp>-march</samp> indicates the instruction set the compiler can use, and there is no common instruction set applicable to all processors. In contrast, <samp>-mtune</samp> indicates the processor (or, in this case, collection of processors) for which the code is optimized. </p>
</dd> </dl> </dd> <dt><code>-mcpu=<var>cpu-type</var></code></dt> <dd> <p id="index-mcpu-15">A deprecated synonym for <samp>-mtune</samp>. </p> </dd> <dt><code>-mfpmath=<var>unit</var></code></dt> <dd> <p id="index-mfpmath-1">Generate floating-point arithmetic for selected unit <var>unit</var>. The choices for <var>unit</var> are: </p> <dl compact> <dt>‘<samp>387</samp>’</dt> <dd>
<p>Use the standard 387 floating-point coprocessor present on the majority of chips and emulated otherwise. Code compiled with this option runs almost everywhere. The temporary results are computed in 80-bit precision instead of the precision specified by the type, resulting in slightly different results compared to most of other chips. See <samp>-ffloat-store</samp> for more detailed description. </p> <p>This is the default choice for non-Darwin x86-32 targets. </p> </dd> <dt>‘<samp>sse</samp>’</dt> <dd>
<p>Use scalar floating-point instructions present in the SSE instruction set. This instruction set is supported by Pentium III and newer chips, and in the AMD line by Athlon-4, Athlon XP and Athlon MP chips. The earlier version of the SSE instruction set supports only single-precision arithmetic, thus the double and extended-precision arithmetic are still done using 387. A later version, present only in Pentium 4 and AMD x86-64 chips, supports double-precision arithmetic too. </p> <p>For the x86-32 compiler, you must use <samp>-march=<var>cpu-type</var></samp>, <samp>-msse</samp> or <samp>-msse2</samp> switches to enable SSE extensions and make this option effective. For the x86-64 compiler, these extensions are enabled by default. </p> <p>The resulting code should be considerably faster in the majority of cases and avoid the numerical instability problems of 387 code, but may break some existing code that expects temporaries to be 80 bits. </p> <p>This is the default choice for the x86-64 compiler, Darwin x86-32 targets, and the default choice for x86-32 targets with the SSE2 instruction set when <samp>-ffast-math</samp> is enabled. </p> </dd> <dt>‘<samp>sse,387</samp>’</dt> <dt>‘<samp>sse+387</samp>’</dt> <dt>‘<samp>both</samp>’</dt> <dd><p>Attempt to utilize both instruction sets at once. This effectively doubles the amount of available registers, and on chips with separate execution units for 387 and SSE the execution resources too. Use this option with care, as it is still experimental, because the GCC register allocator does not model separate functional units well, resulting in unstable performance. </p></dd> </dl> </dd> <dt><code>-masm=<var>dialect</var></code></dt> <dd> <p id="index-masm_003ddialect">Output assembly instructions using selected <var>dialect</var>. Also affects which dialect is used for basic <code>asm</code> (see <a href="basic-asm#Basic-Asm">Basic Asm</a>) and extended <code>asm</code> (see <a href="extended-asm#Extended-Asm">Extended Asm</a>). Supported choices (in dialect order) are ‘<samp>att</samp>’ or ‘<samp>intel</samp>’. The default is ‘<samp>att</samp>’. Darwin does not support ‘<samp>intel</samp>’. </p> </dd> <dt><code>-mieee-fp</code></dt> <dt><code>-mno-ieee-fp</code></dt> <dd>  <p id="index-mno-ieee-fp">Control whether or not the compiler uses IEEE floating-point comparisons. These correctly handle the case where the result of a comparison is unordered. </p> </dd> <dt><code>-m80387</code></dt> <dt><code>-mhard-float</code></dt> <dd>  <p id="index-mhard-float-10">Generate output containing 80387 instructions for floating point. </p> </dd> <dt><code>-mno-80387</code></dt> <dt><code>-msoft-float</code></dt> <dd>  <p id="index-msoft-float-14">Generate output containing library calls for floating point. </p> <p><strong>Warning:</strong> the requisite libraries are not part of GCC. Normally the facilities of the machine’s usual C compiler are used, but this cannot be done directly in cross-compilation. You must make your own arrangements to provide suitable library functions for cross-compilation. </p> <p>On machines where a function returns floating-point results in the 80387 register stack, some floating-point opcodes may be emitted even if <samp>-msoft-float</samp> is used. </p> </dd> <dt><code>-mno-fp-ret-in-387</code></dt> <dd>  <p id="index-mfp-ret-in-387">Do not use the FPU registers for return values of functions. </p> <p>The usual calling convention has functions return values of types <code>float</code> and <code>double</code> in an FPU register, even if there is no FPU. The idea is that the operating system should emulate an FPU. </p> <p>The option <samp>-mno-fp-ret-in-387</samp> causes such values to be returned in ordinary CPU registers instead. </p> </dd> <dt><code>-mno-fancy-math-387</code></dt> <dd>  <p id="index-mfancy-math-387">Some 387 emulators do not support the <code>sin</code>, <code>cos</code> and <code>sqrt</code> instructions for the 387. Specify this option to avoid generating those instructions. This option is overridden when <samp>-march</samp> indicates that the target CPU always has an FPU and so the instruction does not need emulation. These instructions are not generated unless you also use the <samp>-funsafe-math-optimizations</samp> switch. </p> </dd> <dt><code>-malign-double</code></dt> <dt><code>-mno-align-double</code></dt> <dd>  <p id="index-mno-align-double">Control whether GCC aligns <code>double</code>, <code>long double</code>, and <code>long long</code> variables on a two-word boundary or a one-word boundary. Aligning <code>double</code> variables on a two-word boundary produces code that runs somewhat faster on a Pentium at the expense of more memory. </p> <p>On x86-64, <samp>-malign-double</samp> is enabled by default. </p> <p><strong>Warning:</strong> if you use the <samp>-malign-double</samp> switch, structures containing the above types are aligned differently than the published application binary interface specifications for the x86-32 and are not binary compatible with structures in code compiled without that switch. </p> </dd> <dt><code>-m96bit-long-double</code></dt> <dt><code>-m128bit-long-double</code></dt> <dd>  <p id="index-m128bit-long-double">These switches control the size of <code>long double</code> type. The x86-32 application binary interface specifies the size to be 96 bits, so <samp>-m96bit-long-double</samp> is the default in 32-bit mode. </p> <p>Modern architectures (Pentium and newer) prefer <code>long double</code> to be aligned to an 8- or 16-byte boundary. In arrays or structures conforming to the ABI, this is not possible. So specifying <samp>-m128bit-long-double</samp> aligns <code>long double</code> to a 16-byte boundary by padding the <code>long double</code> with an additional 32-bit zero. </p> <p>In the x86-64 compiler, <samp>-m128bit-long-double</samp> is the default choice as its ABI specifies that <code>long double</code> is aligned on 16-byte boundary. </p> <p>Notice that neither of these options enable any extra precision over the x87 standard of 80 bits for a <code>long double</code>. </p> <p><strong>Warning:</strong> if you override the default value for your target ABI, this changes the size of structures and arrays containing <code>long double</code> variables, as well as modifying the function calling convention for functions taking <code>long double</code>. Hence they are not binary-compatible with code compiled without that switch. </p> </dd> <dt><code>-mlong-double-64</code></dt> <dt><code>-mlong-double-80</code></dt> <dt><code>-mlong-double-128</code></dt> <dd>   <p id="index-mlong-double-128-1">These switches control the size of <code>long double</code> type. A size of 64 bits makes the <code>long double</code> type equivalent to the <code>double</code> type. This is the default for 32-bit Bionic C library. A size of 128 bits makes the <code>long double</code> type equivalent to the <code>__float128</code> type. This is the default for 64-bit Bionic C library. </p> <p><strong>Warning:</strong> if you override the default value for your target ABI, this changes the size of structures and arrays containing <code>long double</code> variables, as well as modifying the function calling convention for functions taking <code>long double</code>. Hence they are not binary-compatible with code compiled without that switch. </p> </dd> <dt><code>-malign-data=<var>type</var></code></dt> <dd> <p id="index-malign-data">Control how GCC aligns variables. Supported values for <var>type</var> are ‘<samp>compat</samp>’ uses increased alignment value compatible uses GCC 4.8 and earlier, ‘<samp>abi</samp>’ uses alignment value as specified by the psABI, and ‘<samp>cacheline</samp>’ uses increased alignment value to match the cache line size. ‘<samp>compat</samp>’ is the default. </p> </dd> <dt><code>-mlarge-data-threshold=<var>threshold</var></code></dt> <dd> <p id="index-mlarge-data-threshold">When <samp>-mcmodel=medium</samp> is specified, data objects larger than <var>threshold</var> are placed in the large data section. This value must be the same across all objects linked into the binary, and defaults to 65535. </p> </dd> <dt><code>-mrtd</code></dt> <dd> <p id="index-mrtd-1">Use a different function-calling convention, in which functions that take a fixed number of arguments return with the <code>ret <var>num</var></code> instruction, which pops their arguments while returning. This saves one instruction in the caller since there is no need to pop the arguments there. </p> <p>You can specify that an individual function is called with this calling sequence with the function attribute <code>stdcall</code>. You can also override the <samp>-mrtd</samp> option by using the function attribute <code>cdecl</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> <p><strong>Warning:</strong> this calling convention is incompatible with the one normally used on Unix, so you cannot use it if you need to call libraries compiled with the Unix compiler. </p> <p>Also, you must provide function prototypes for all functions that take variable numbers of arguments (including <code>printf</code>); otherwise incorrect code is generated for calls to those functions. </p> <p>In addition, seriously incorrect code results if you call a function with too many arguments. (Normally, extra arguments are harmlessly ignored.) </p> </dd> <dt><code>-mregparm=<var>num</var></code></dt> <dd> <p id="index-mregparm">Control how many registers are used to pass integer arguments. By default, no registers are used to pass arguments, and at most 3 registers can be used. You can control this behavior for a specific function by using the function attribute <code>regparm</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> <p><strong>Warning:</strong> if you use this switch, and <var>num</var> is nonzero, then you must build all modules with the same value, including any libraries. This includes the system libraries and startup modules. </p> </dd> <dt><code>-msseregparm</code></dt> <dd> <p id="index-msseregparm">Use SSE register passing conventions for float and double arguments and return values. You can control this behavior for a specific function by using the function attribute <code>sseregparm</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> <p><strong>Warning:</strong> if you use this switch then you must build all modules with the same value, including any libraries. This includes the system libraries and startup modules. </p> </dd> <dt><code>-mvect8-ret-in-mem</code></dt> <dd> <p id="index-mvect8-ret-in-mem">Return 8-byte vectors in memory instead of MMX registers. This is the default on Solaris 8 and 9 and VxWorks to match the ABI of the Sun Studio compilers until version 12. Later compiler versions (starting with Studio 12 Update 1) follow the ABI used by other x86 targets, which is the default on Solaris 10 and later. <em>Only</em> use this option if you need to remain compatible with existing code produced by those previous compiler versions or older versions of GCC. </p> </dd> <dt><code>-mpc32</code></dt> <dt><code>-mpc64</code></dt> <dt><code>-mpc80</code></dt> <dd>   <p id="index-mpc80">Set 80387 floating-point precision to 32, 64 or 80 bits. When <samp>-mpc32</samp> is specified, the significands of results of floating-point operations are rounded to 24 bits (single precision); <samp>-mpc64</samp> rounds the significands of results of floating-point operations to 53 bits (double precision) and <samp>-mpc80</samp> rounds the significands of results of floating-point operations to 64 bits (extended double precision), which is the default. When this option is used, floating-point operations in higher precisions are not available to the programmer without setting the FPU control word explicitly. </p> <p>Setting the rounding of floating-point operations to less than the default 80 bits can speed some programs by 2% or more. Note that some mathematical libraries assume that extended-precision (80-bit) floating-point operations are enabled by default; routines in such libraries could suffer significant loss of accuracy, typically through so-called “catastrophic cancellation”, when this option is used to set the precision to less than extended precision. </p> </dd> <dt><code>-mstackrealign</code></dt> <dd> <p id="index-mstackrealign">Realign the stack at entry. On the x86, the <samp>-mstackrealign</samp> option generates an alternate prologue and epilogue that realigns the run-time stack if necessary. This supports mixing legacy codes that keep 4-byte stack alignment with modern codes that keep 16-byte stack alignment for SSE compatibility. See also the attribute <code>force_align_arg_pointer</code>, applicable to individual functions. </p> </dd> <dt><code>-mpreferred-stack-boundary=<var>num</var></code></dt> <dd> <p id="index-mpreferred-stack-boundary-1">Attempt to keep the stack boundary aligned to a 2 raised to <var>num</var> byte boundary. If <samp>-mpreferred-stack-boundary</samp> is not specified, the default is 4 (16 bytes or 128 bits). </p> <p><strong>Warning:</strong> When generating code for the x86-64 architecture with SSE extensions disabled, <samp>-mpreferred-stack-boundary=3</samp> can be used to keep the stack boundary aligned to 8 byte boundary. Since x86-64 ABI require 16 byte stack alignment, this is ABI incompatible and intended to be used in controlled environment where stack space is important limitation. This option leads to wrong code when functions compiled with 16 byte stack alignment (such as functions from a standard library) are called with misaligned stack. In this case, SSE instructions may lead to misaligned memory access traps. In addition, variable arguments are handled incorrectly for 16 byte aligned objects (including x87 long double and __int128), leading to wrong results. You must build all modules with <samp>-mpreferred-stack-boundary=3</samp>, including any libraries. This includes the system libraries and startup modules. </p> </dd> <dt><code>-mincoming-stack-boundary=<var>num</var></code></dt> <dd> <p id="index-mincoming-stack-boundary">Assume the incoming stack is aligned to a 2 raised to <var>num</var> byte boundary. If <samp>-mincoming-stack-boundary</samp> is not specified, the one specified by <samp>-mpreferred-stack-boundary</samp> is used. </p> <p>On Pentium and Pentium Pro, <code>double</code> and <code>long double</code> values should be aligned to an 8-byte boundary (see <samp>-malign-double</samp>) or suffer significant run time performance penalties. On Pentium III, the Streaming SIMD Extension (SSE) data type <code>__m128</code> may not work properly if it is not 16-byte aligned. </p> <p>To ensure proper alignment of this values on the stack, the stack boundary must be as aligned as that required by any value stored on the stack. Further, every function must be generated such that it keeps the stack aligned. Thus calling a function compiled with a higher preferred stack boundary from a function compiled with a lower preferred stack boundary most likely misaligns the stack. It is recommended that libraries that use callbacks always use the default setting. </p> <p>This extra alignment does consume extra stack space, and generally increases code size. Code that is sensitive to stack space usage, such as embedded systems and operating system kernels, may want to reduce the preferred alignment to <samp>-mpreferred-stack-boundary=2</samp>. </p> </dd> <dt><code>-mmmx</code></dt>  <dt><code>-msse</code></dt>  <dt><code>-msse2</code></dt>  <dt><code>-msse3</code></dt>  <dt><code>-mssse3</code></dt>  <dt><code>-msse4</code></dt>  <dt><code>-msse4a</code></dt>  <dt><code>-msse4.1</code></dt>  <dt><code>-msse4.2</code></dt>  <dt><code>-mavx</code></dt>  <dt><code>-mavx2</code></dt>  <dt><code>-mavx512f</code></dt>  <dt><code>-mavx512pf</code></dt>  <dt><code>-mavx512er</code></dt>  <dt><code>-mavx512cd</code></dt>  <dt><code>-mavx512vl</code></dt>  <dt><code>-mavx512bw</code></dt>  <dt><code>-mavx512dq</code></dt>  <dt><code>-mavx512ifma</code></dt>  <dt><code>-mavx512vbmi</code></dt>  <dt><code>-msha</code></dt>  <dt><code>-maes</code></dt>  <dt><code>-mpclmul</code></dt>  <dt><code>-mclflushopt</code></dt>  <dt><code>-mclwb</code></dt>  <dt><code>-mfsgsbase</code></dt>  <dt><code>-mptwrite</code></dt>  <dt><code>-mrdrnd</code></dt>  <dt><code>-mf16c</code></dt>  <dt><code>-mfma</code></dt>  <dt><code>-mpconfig</code></dt>  <dt><code>-mwbnoinvd</code></dt>  <dt><code>-mfma4</code></dt>  <dt><code>-mprfchw</code></dt>  <dt><code>-mrdpid</code></dt>  <dt><code>-mprefetchwt1</code></dt>  <dt><code>-mrdseed</code></dt>  <dt><code>-msgx</code></dt>  <dt><code>-mxop</code></dt>  <dt><code>-mlwp</code></dt>  <dt><code>-m3dnow</code></dt>  <dt><code>-m3dnowa</code></dt>  <dt><code>-mpopcnt</code></dt>  <dt><code>-mabm</code></dt>  <dt><code>-madx</code></dt>  <dt><code>-mbmi</code></dt>  <dt><code>-mbmi2</code></dt>  <dt><code>-mlzcnt</code></dt>  <dt><code>-mfxsr</code></dt>  <dt><code>-mxsave</code></dt>  <dt><code>-mxsaveopt</code></dt>  <dt><code>-mxsavec</code></dt>  <dt><code>-mxsaves</code></dt>  <dt><code>-mrtm</code></dt>  <dt><code>-mhle</code></dt>  <dt><code>-mtbm</code></dt>  <dt><code>-mmwaitx</code></dt>  <dt><code>-mclzero</code></dt>  <dt><code>-mpku</code></dt>  <dt><code>-mavx512vbmi2</code></dt>  <dt><code>-mgfni</code></dt>  <dt><code>-mvaes</code></dt>  <dt><code>-mwaitpkg</code></dt>  <dt><code>-mvpclmulqdq</code></dt>  <dt><code>-mavx512bitalg</code></dt>  <dt><code>-mmovdiri</code></dt>  <dt><code>-mmovdir64b</code></dt>  <dt><code>-mavx512vpopcntdq</code></dt>  <dt><code>-mavx5124fmaps</code></dt>  <dt><code>-mavx512vnni</code></dt>  <dt><code>-mavx5124vnniw</code></dt>  <dt><code>-mcldemote</code></dt> <dd> <p id="index-mcldemote">These switches enable the use of instructions in the MMX, SSE, SSE2, SSE3, SSSE3, SSE4, SSE4A, SSE4.1, SSE4.2, AVX, AVX2, AVX512F, AVX512PF, AVX512ER, AVX512CD, AVX512VL, AVX512BW, AVX512DQ, AVX512IFMA, AVX512VBMI, SHA, AES, PCLMUL, CLFLUSHOPT, CLWB, FSGSBASE, PTWRITE, RDRND, F16C, FMA, PCONFIG, WBNOINVD, FMA4, PREFETCHW, RDPID, PREFETCHWT1, RDSEED, SGX, XOP, LWP, 3DNow!, enhanced 3DNow!, POPCNT, ABM, ADX, BMI, BMI2, LZCNT, FXSR, XSAVE, XSAVEOPT, XSAVEC, XSAVES, RTM, HLE, TBM, MWAITX, CLZERO, PKU, AVX512VBMI2, GFNI, VAES, WAITPKG, VPCLMULQDQ, AVX512BITALG, MOVDIRI, MOVDIR64B, AVX512VPOPCNTDQ, AVX5124FMAPS, AVX512VNNI, AVX5124VNNIW, or CLDEMOTE extended instruction sets. Each has a corresponding <samp>-mno-</samp> option to disable use of these instructions. </p> <p>These extensions are also available as built-in functions: see <a href="x86-built-in-functions#x86-Built-in-Functions">x86 Built-in Functions</a>, for details of the functions enabled and disabled by these switches. </p> <p>To generate SSE/SSE2 instructions automatically from floating-point code (as opposed to 387 instructions), see <samp>-mfpmath=sse</samp>. </p> <p>GCC depresses SSEx instructions when <samp>-mavx</samp> is used. Instead, it generates new AVX instructions or AVX equivalence for all SSEx instructions when needed. </p> <p>These options enable GCC to use these extended instructions in generated code, even without <samp>-mfpmath=sse</samp>. Applications that perform run-time CPU detection must compile separate files for each supported architecture, using the appropriate flags. In particular, the file containing the CPU detection code should be compiled without these options. </p> </dd> <dt><code>-mdump-tune-features</code></dt> <dd> <p id="index-mdump-tune-features">This option instructs GCC to dump the names of the x86 performance tuning features and default settings. The names can be used in <samp>-mtune-ctrl=<var>feature-list</var></samp>. </p> </dd> <dt><code>-mtune-ctrl=<var>feature-list</var></code></dt> <dd> <p id="index-mtune-ctrl_003dfeature-list">This option is used to do fine grain control of x86 code generation features. <var>feature-list</var> is a comma separated list of <var>feature</var> names. See also <samp>-mdump-tune-features</samp>. When specified, the <var>feature</var> is turned on if it is not preceded with ‘<samp>^</samp>’, otherwise, it is turned off. <samp>-mtune-ctrl=<var>feature-list</var></samp> is intended to be used by GCC developers. Using it may lead to code paths not covered by testing and can potentially result in compiler ICEs or runtime errors. </p> </dd> <dt><code>-mno-default</code></dt> <dd> <p id="index-mno-default">This option instructs GCC to turn off all tunable features. See also <samp>-mtune-ctrl=<var>feature-list</var></samp> and <samp>-mdump-tune-features</samp>. </p> </dd> <dt><code>-mcld</code></dt> <dd> <p id="index-mcld">This option instructs GCC to emit a <code>cld</code> instruction in the prologue of functions that use string instructions. String instructions depend on the DF flag to select between autoincrement or autodecrement mode. While the ABI specifies the DF flag to be cleared on function entry, some operating systems violate this specification by not clearing the DF flag in their exception dispatchers. The exception handler can be invoked with the DF flag set, which leads to wrong direction mode when string instructions are used. This option can be enabled by default on 32-bit x86 targets by configuring GCC with the <samp>--enable-cld</samp> configure option. Generation of <code>cld</code> instructions can be suppressed with the <samp>-mno-cld</samp> compiler option in this case. </p> </dd> <dt><code>-mvzeroupper</code></dt> <dd> <p id="index-mvzeroupper">This option instructs GCC to emit a <code>vzeroupper</code> instruction before a transfer of control flow out of the function to minimize the AVX to SSE transition penalty as well as remove unnecessary <code>zeroupper</code> intrinsics. </p> </dd> <dt><code>-mprefer-avx128</code></dt> <dd> <p id="index-mprefer-avx128">This option instructs GCC to use 128-bit AVX instructions instead of 256-bit AVX instructions in the auto-vectorizer. </p> </dd> <dt><code>-mprefer-vector-width=<var>opt</var></code></dt> <dd> <p id="index-mprefer-vector-width">This option instructs GCC to use <var>opt</var>-bit vector width in instructions instead of default on the selected platform. </p> <dl compact> <dt>‘<samp>none</samp>’</dt> <dd>
<p>No extra limitations applied to GCC other than defined by the selected platform. </p> </dd> <dt>‘<samp>128</samp>’</dt> <dd>
<p>Prefer 128-bit vector width for instructions. </p> </dd> <dt>‘<samp>256</samp>’</dt> <dd>
<p>Prefer 256-bit vector width for instructions. </p> </dd> <dt>‘<samp>512</samp>’</dt> <dd><p>Prefer 512-bit vector width for instructions. </p></dd> </dl> </dd> <dt><code>-mcx16</code></dt> <dd> <p id="index-mcx16">This option enables GCC to generate <code>CMPXCHG16B</code> instructions in 64-bit code to implement compare-and-exchange operations on 16-byte aligned 128-bit objects. This is useful for atomic updates of data structures exceeding one machine word in size. The compiler uses this instruction to implement <a href="_005f_005fsync-builtins#g_t_005f_005fsync-Builtins">__sync Builtins</a>. However, for <a href="_005f_005fatomic-builtins#g_t_005f_005fatomic-Builtins">__atomic Builtins</a> operating on 128-bit integers, a library call is always used. </p> </dd> <dt><code>-msahf</code></dt> <dd> <p id="index-msahf">This option enables generation of <code>SAHF</code> instructions in 64-bit code. Early Intel Pentium 4 CPUs with Intel 64 support, prior to the introduction of Pentium 4 G1 step in December 2005, lacked the <code>LAHF</code> and <code>SAHF</code> instructions which are supported by AMD64. These are load and store instructions, respectively, for certain status flags. In 64-bit mode, the <code>SAHF</code> instruction is used to optimize <code>fmod</code>, <code>drem</code>, and <code>remainder</code> built-in functions; see <a href="other-builtins#Other-Builtins">Other Builtins</a> for details. </p> </dd> <dt><code>-mmovbe</code></dt> <dd> <p id="index-mmovbe">This option enables use of the <code>movbe</code> instruction to implement <code>__builtin_bswap32</code> and <code>__builtin_bswap64</code>. </p> </dd> <dt><code>-mshstk</code></dt> <dd> <p id="index-mshstk">The <samp>-mshstk</samp> option enables shadow stack built-in functions from x86 Control-flow Enforcement Technology (CET). </p> </dd> <dt><code>-mcrc32</code></dt> <dd> <p id="index-mcrc32">This option enables built-in functions <code>__builtin_ia32_crc32qi</code>, <code>__builtin_ia32_crc32hi</code>, <code>__builtin_ia32_crc32si</code> and <code>__builtin_ia32_crc32di</code> to generate the <code>crc32</code> machine instruction. </p> </dd> <dt><code>-mrecip</code></dt> <dd> <p id="index-mrecip-1">This option enables use of <code>RCPSS</code> and <code>RSQRTSS</code> instructions (and their vectorized variants <code>RCPPS</code> and <code>RSQRTPS</code>) with an additional Newton-Raphson step to increase precision instead of <code>DIVSS</code> and <code>SQRTSS</code> (and their vectorized variants) for single-precision floating-point arguments. These instructions are generated only when <samp>-funsafe-math-optimizations</samp> is enabled together with <samp>-ffinite-math-only</samp> and <samp>-fno-trapping-math</samp>. Note that while the throughput of the sequence is higher than the throughput of the non-reciprocal instruction, the precision of the sequence can be decreased by up to 2 ulp (i.e. the inverse of 1.0 equals 0.99999994). </p> <p>Note that GCC implements <code>1.0f/sqrtf(<var>x</var>)</code> in terms of <code>RSQRTSS</code> (or <code>RSQRTPS</code>) already with <samp>-ffast-math</samp> (or the above option combination), and doesn’t need <samp>-mrecip</samp>. </p> <p>Also note that GCC emits the above sequence with additional Newton-Raphson step for vectorized single-float division and vectorized <code>sqrtf(<var>x</var>)</code> already with <samp>-ffast-math</samp> (or the above option combination), and doesn’t need <samp>-mrecip</samp>. </p> </dd> <dt><code>-mrecip=<var>opt</var></code></dt> <dd> <p id="index-mrecip_003dopt-1">This option controls which reciprocal estimate instructions may be used. <var>opt</var> is a comma-separated list of options, which may be preceded by a ‘<samp>!</samp>’ to invert the option: </p> <dl compact> <dt>‘<samp>all</samp>’</dt> <dd>
<p>Enable all estimate instructions. </p> </dd> <dt>‘<samp>default</samp>’</dt> <dd>
<p>Enable the default instructions, equivalent to <samp>-mrecip</samp>. </p> </dd> <dt>‘<samp>none</samp>’</dt> <dd>
<p>Disable all estimate instructions, equivalent to <samp>-mno-recip</samp>. </p> </dd> <dt>‘<samp>div</samp>’</dt> <dd>
<p>Enable the approximation for scalar division. </p> </dd> <dt>‘<samp>vec-div</samp>’</dt> <dd>
<p>Enable the approximation for vectorized division. </p> </dd> <dt>‘<samp>sqrt</samp>’</dt> <dd>
<p>Enable the approximation for scalar square root. </p> </dd> <dt>‘<samp>vec-sqrt</samp>’</dt> <dd><p>Enable the approximation for vectorized square root. </p></dd> </dl> <p>So, for example, <samp>-mrecip=all,!sqrt</samp> enables all of the reciprocal approximations, except for square root. </p> </dd> <dt><code>-mveclibabi=<var>type</var></code></dt> <dd> <p id="index-mveclibabi-1">Specifies the ABI type to use for vectorizing intrinsics using an external library. Supported values for <var>type</var> are ‘<samp>svml</samp>’ for the Intel short vector math library and ‘<samp>acml</samp>’ for the AMD math core library. To use this option, both <samp>-ftree-vectorize</samp> and <samp>-funsafe-math-optimizations</samp> have to be enabled, and an SVML or ACML ABI-compatible library must be specified at link time. </p> <p>GCC currently emits calls to <code>vmldExp2</code>, <code>vmldLn2</code>, <code>vmldLog102</code>, <code>vmldPow2</code>, <code>vmldTanh2</code>, <code>vmldTan2</code>, <code>vmldAtan2</code>, <code>vmldAtanh2</code>, <code>vmldCbrt2</code>, <code>vmldSinh2</code>, <code>vmldSin2</code>, <code>vmldAsinh2</code>, <code>vmldAsin2</code>, <code>vmldCosh2</code>, <code>vmldCos2</code>, <code>vmldAcosh2</code>, <code>vmldAcos2</code>, <code>vmlsExp4</code>, <code>vmlsLn4</code>, <code>vmlsLog104</code>, <code>vmlsPow4</code>, <code>vmlsTanh4</code>, <code>vmlsTan4</code>, <code>vmlsAtan4</code>, <code>vmlsAtanh4</code>, <code>vmlsCbrt4</code>, <code>vmlsSinh4</code>, <code>vmlsSin4</code>, <code>vmlsAsinh4</code>, <code>vmlsAsin4</code>, <code>vmlsCosh4</code>, <code>vmlsCos4</code>, <code>vmlsAcosh4</code> and <code>vmlsAcos4</code> for corresponding function type when <samp>-mveclibabi=svml</samp> is used, and <code>__vrd2_sin</code>, <code>__vrd2_cos</code>, <code>__vrd2_exp</code>, <code>__vrd2_log</code>, <code>__vrd2_log2</code>, <code>__vrd2_log10</code>, <code>__vrs4_sinf</code>, <code>__vrs4_cosf</code>, <code>__vrs4_expf</code>, <code>__vrs4_logf</code>, <code>__vrs4_log2f</code>, <code>__vrs4_log10f</code> and <code>__vrs4_powf</code> for the corresponding function type when <samp>-mveclibabi=acml</samp> is used. </p> </dd> <dt><code>-mabi=<var>name</var></code></dt> <dd> <p id="index-mabi-4">Generate code for the specified calling convention. Permissible values are ‘<samp>sysv</samp>’ for the ABI used on GNU/Linux and other systems, and ‘<samp>ms</samp>’ for the Microsoft ABI. The default is to use the Microsoft ABI when targeting Microsoft Windows and the SysV ABI on all other systems. You can control this behavior for specific functions by using the function attributes <code>ms_abi</code> and <code>sysv_abi</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> </dd> <dt><code>-mforce-indirect-call</code></dt> <dd> <p id="index-mforce-indirect-call">Force all calls to functions to be indirect. This is useful when using Intel Processor Trace where it generates more precise timing information for function calls. </p> </dd> <dt><code>-mmanual-endbr</code></dt> <dd> <p id="index-mmanual-endbr">Insert ENDBR instruction at function entry only via the <code>cf_check</code> function attribute. This is useful when used with the option <samp>-fcf-protection=branch</samp> to control ENDBR insertion at the function entry. </p> </dd> <dt><code>-mcall-ms2sysv-xlogues</code></dt> <dd>  <p id="index-mno-call-ms2sysv-xlogues">Due to differences in 64-bit ABIs, any Microsoft ABI function that calls a System V ABI function must consider RSI, RDI and XMM6-15 as clobbered. By default, the code for saving and restoring these registers is emitted inline, resulting in fairly lengthy prologues and epilogues. Using <samp>-mcall-ms2sysv-xlogues</samp> emits prologues and epilogues that use stubs in the static portion of libgcc to perform these saves and restores, thus reducing function size at the cost of a few extra instructions. </p> </dd> <dt><code>-mtls-dialect=<var>type</var></code></dt> <dd> <p id="index-mtls-dialect-1">Generate code to access thread-local storage using the ‘<samp>gnu</samp>’ or ‘<samp>gnu2</samp>’ conventions. ‘<samp>gnu</samp>’ is the conservative default; ‘<samp>gnu2</samp>’ is more efficient, but it may add compile- and run-time requirements that cannot be satisfied on all systems. </p> </dd> <dt><code>-mpush-args</code></dt> <dt><code>-mno-push-args</code></dt> <dd>  <p id="index-mno-push-args">Use PUSH operations to store outgoing parameters. This method is shorter and usually equally fast as method using SUB/MOV operations and is enabled by default. In some cases disabling it may improve performance because of improved scheduling and reduced dependencies. </p> </dd> <dt><code>-maccumulate-outgoing-args</code></dt> <dd> <p id="index-maccumulate-outgoing-args-1">If enabled, the maximum amount of space required for outgoing arguments is computed in the function prologue. This is faster on most modern CPUs because of reduced dependencies, improved scheduling and reduced stack usage when the preferred stack boundary is not equal to 2. The drawback is a notable increase in code size. This switch implies <samp>-mno-push-args</samp>. </p> </dd> <dt><code>-mthreads</code></dt> <dd> <p id="index-mthreads">Support thread-safe exception handling on MinGW. Programs that rely on thread-safe exception handling must compile and link all code with the <samp>-mthreads</samp> option. When compiling, <samp>-mthreads</samp> defines <samp>-D_MT</samp>; when linking, it links in a special thread helper library <samp>-lmingwthrd</samp> which cleans up per-thread exception-handling data. </p> </dd> <dt><code>-mms-bitfields</code></dt> <dt><code>-mno-ms-bitfields</code></dt> <dd>  <p id="index-mno-ms-bitfields">Enable/disable bit-field layout compatible with the native Microsoft Windows compiler. </p> <p>If <code>packed</code> is used on a structure, or if bit-fields are used, it may be that the Microsoft ABI lays out the structure differently than the way GCC normally does. Particularly when moving packed data between functions compiled with GCC and the native Microsoft compiler (either via function call or as data in a file), it may be necessary to access either format. </p> <p>This option is enabled by default for Microsoft Windows targets. This behavior can also be controlled locally by use of variable or type attributes. For more information, see <a href="variable-attributes#x86-Variable-Attributes">x86 Variable Attributes</a> and <a href="type-attributes#x86-Type-Attributes">x86 Type Attributes</a>. </p> <p>The Microsoft structure layout algorithm is fairly simple with the exception of the bit-field packing. The padding and alignment of members of structures and whether a bit-field can straddle a storage-unit boundary are determine by these rules: </p> <ol> <li> Structure members are stored sequentially in the order in which they are declared: the first member has the lowest memory address and the last member the highest. </li>
<li> Every data object has an alignment requirement. The alignment requirement for all data except structures, unions, and arrays is either the size of the object or the current packing size (specified with either the <code>aligned</code> attribute or the <code>pack</code> pragma), whichever is less. For structures, unions, and arrays, the alignment requirement is the largest alignment requirement of its members. Every object is allocated an offset so that: <div class="smallexample"> <pre class="smallexample" data-language="cpp">offset % alignment_requirement == 0</pre>
</div> </li>
<li> Adjacent bit-fields are packed into the same 1-, 2-, or 4-byte allocation unit if the integral types are the same size and if the next bit-field fits into the current allocation unit without crossing the boundary imposed by the common alignment requirements of the bit-fields. </li>
</ol> <p>MSVC interprets zero-length bit-fields in the following ways: </p> <ol> <li> If a zero-length bit-field is inserted between two bit-fields that are normally coalesced, the bit-fields are not coalesced. <p>For example: </p> <div class="smallexample"> <pre class="smallexample" data-language="cpp">struct
 {
   unsigned long bf_1 : 12;
   unsigned long : 0;
   unsigned long bf_2 : 12;
 } t1;</pre>
</div> <p>The size of <code>t1</code> is 8 bytes with the zero-length bit-field. If the zero-length bit-field were removed, <code>t1</code>’s size would be 4 bytes. </p> </li>
<li> If a zero-length bit-field is inserted after a bit-field, <code>foo</code>, and the alignment of the zero-length bit-field is greater than the member that follows it, <code>bar</code>, <code>bar</code> is aligned as the type of the zero-length bit-field. <p>For example: </p> <div class="smallexample"> <pre class="smallexample" data-language="cpp">struct
 {
   char foo : 4;
   short : 0;
   char bar;
 } t2;

struct
 {
   char foo : 4;
   short : 0;
   double bar;
 } t3;</pre>
</div> <p>For <code>t2</code>, <code>bar</code> is placed at offset 2, rather than offset 1. Accordingly, the size of <code>t2</code> is 4. For <code>t3</code>, the zero-length bit-field does not affect the alignment of <code>bar</code> or, as a result, the size of the structure. </p> <p>Taking this into account, it is important to note the following: </p> <ol> <li> If a zero-length bit-field follows a normal bit-field, the type of the zero-length bit-field may affect the alignment of the structure as whole. For example, <code>t2</code> has a size of 4 bytes, since the zero-length bit-field follows a normal bit-field, and is of type short. </li>
<li> Even if a zero-length bit-field is not followed by a normal bit-field, it may still affect the alignment of the structure: <div class="smallexample"> <pre class="smallexample" data-language="cpp">struct
 {
   char foo : 6;
   long : 0;
 } t4;</pre>
</div> <p>Here, <code>t4</code> takes up 4 bytes. </p>
</li>
</ol> </li>
<li> Zero-length bit-fields following non-bit-field members are ignored: <div class="smallexample"> <pre class="smallexample" data-language="cpp">struct
 {
   char foo;
   long : 0;
   char bar;
 } t5;</pre>
</div> <p>Here, <code>t5</code> takes up 2 bytes. </p>
</li>
</ol> </dd> <dt><code>-mno-align-stringops</code></dt> <dd>  <p id="index-malign-stringops">Do not align the destination of inlined string operations. This switch reduces code size and improves performance in case the destination is already aligned, but GCC doesn’t know about it. </p> </dd> <dt><code>-minline-all-stringops</code></dt> <dd> <p id="index-minline-all-stringops">By default GCC inlines string operations only when the destination is known to be aligned to least a 4-byte boundary. This enables more inlining and increases code size, but may improve performance of code that depends on fast <code>memcpy</code>, <code>strlen</code>, and <code>memset</code> for short lengths. </p> </dd> <dt><code>-minline-stringops-dynamically</code></dt> <dd> <p id="index-minline-stringops-dynamically">For string operations of unknown size, use run-time checks with inline code for small blocks and a library call for large blocks. </p> </dd> <dt><code>-mstringop-strategy=<var>alg</var></code></dt> <dd> <p id="index-mstringop-strategy_003dalg">Override the internal decision heuristic for the particular algorithm to use for inlining string operations. The allowed values for <var>alg</var> are: </p> <dl compact> <dt>‘<samp>rep_byte</samp>’</dt> <dt>‘<samp>rep_4byte</samp>’</dt> <dt>‘<samp>rep_8byte</samp>’</dt> <dd>
<p>Expand using i386 <code>rep</code> prefix of the specified size. </p> </dd> <dt>‘<samp>byte_loop</samp>’</dt> <dt>‘<samp>loop</samp>’</dt> <dt>‘<samp>unrolled_loop</samp>’</dt> <dd>
<p>Expand into an inline loop. </p> </dd> <dt>‘<samp>libcall</samp>’</dt> <dd><p>Always use a library call. </p></dd> </dl> </dd> <dt><code>-mmemcpy-strategy=<var>strategy</var></code></dt> <dd> <p id="index-mmemcpy-strategy_003dstrategy">Override the internal decision heuristic to decide if <code>__builtin_memcpy</code> should be inlined and what inline algorithm to use when the expected size of the copy operation is known. <var>strategy</var> is a comma-separated list of <var>alg</var>:<var>max_size</var>:<var>dest_align</var> triplets. <var>alg</var> is specified in <samp>-mstringop-strategy</samp>, <var>max_size</var> specifies the max byte size with which inline algorithm <var>alg</var> is allowed. For the last triplet, the <var>max_size</var> must be <code>-1</code>. The <var>max_size</var> of the triplets in the list must be specified in increasing order. The minimal byte size for <var>alg</var> is <code>0</code> for the first triplet and <code><var>max_size</var> + 1</code> of the preceding range. </p> </dd> <dt><code>-mmemset-strategy=<var>strategy</var></code></dt> <dd> <p id="index-mmemset-strategy_003dstrategy">The option is similar to <samp>-mmemcpy-strategy=</samp> except that it is to control <code>__builtin_memset</code> expansion. </p> </dd> <dt><code>-momit-leaf-frame-pointer</code></dt> <dd> <p id="index-momit-leaf-frame-pointer-2">Don’t keep the frame pointer in a register for leaf functions. This avoids the instructions to save, set up, and restore frame pointers and makes an extra register available in leaf functions. The option <samp>-fomit-leaf-frame-pointer</samp> removes the frame pointer for leaf functions, which might make debugging harder. </p> </dd> <dt><code>-mtls-direct-seg-refs</code></dt> <dt><code>-mno-tls-direct-seg-refs</code></dt> <dd> <p id="index-mtls-direct-seg-refs">Controls whether TLS variables may be accessed with offsets from the TLS segment register (<code>%gs</code> for 32-bit, <code>%fs</code> for 64-bit), or whether the thread base pointer must be added. Whether or not this is valid depends on the operating system, and whether it maps the segment to cover the entire TLS area. </p> <p>For systems that use the GNU C Library, the default is on. </p> </dd> <dt><code>-msse2avx</code></dt> <dt><code>-mno-sse2avx</code></dt> <dd> <p id="index-msse2avx">Specify that the assembler should encode SSE instructions with VEX prefix. The option <samp>-mavx</samp> turns this on by default. </p> </dd> <dt><code>-mfentry</code></dt> <dt><code>-mno-fentry</code></dt> <dd> <p id="index-mfentry">If profiling is active (<samp>-pg</samp>), put the profiling counter call before the prologue. Note: On x86 architectures the attribute <code>ms_hook_prologue</code> isn’t possible at the moment for <samp>-mfentry</samp> and <samp>-pg</samp>. </p> </dd> <dt><code>-mrecord-mcount</code></dt> <dt><code>-mno-record-mcount</code></dt> <dd> <p id="index-mrecord-mcount">If profiling is active (<samp>-pg</samp>), generate a __mcount_loc section that contains pointers to each profiling call. This is useful for automatically patching and out calls. </p> </dd> <dt><code>-mnop-mcount</code></dt> <dt><code>-mno-nop-mcount</code></dt> <dd> <p id="index-mnop-mcount">If profiling is active (<samp>-pg</samp>), generate the calls to the profiling functions as NOPs. This is useful when they should be patched in later dynamically. This is likely only useful together with <samp>-mrecord-mcount</samp>. </p> </dd> <dt><code>-minstrument-return=<var>type</var></code></dt> <dd> <p id="index-minstrument-return">Instrument function exit in -pg -mfentry instrumented functions with call to specified function. This only instruments true returns ending with ret, but not sibling calls ending with jump. Valid types are <var>none</var> to not instrument, <var>call</var> to generate a call to __return__, or <var>nop5</var> to generate a 5 byte nop. </p> </dd> <dt><code>-mrecord-return</code></dt> <dt><code>-mno-record-return</code></dt> <dd> <p id="index-mrecord-return">Generate a __return_loc section pointing to all return instrumentation code. </p> </dd> <dt><code>-mfentry-name=<var>name</var></code></dt> <dd> <p id="index-mfentry-name">Set name of __fentry__ symbol called at function entry for -pg -mfentry functions. </p> </dd> <dt><code>-mfentry-section=<var>name</var></code></dt> <dd> <p id="index-mfentry-section">Set name of section to record -mrecord-mcount calls (default __mcount_loc). </p> </dd> <dt><code>-mskip-rax-setup</code></dt> <dt><code>-mno-skip-rax-setup</code></dt> <dd> <p id="index-mskip-rax-setup">When generating code for the x86-64 architecture with SSE extensions disabled, <samp>-mskip-rax-setup</samp> can be used to skip setting up RAX register when there are no variable arguments passed in vector registers. </p> <p><strong>Warning:</strong> Since RAX register is used to avoid unnecessarily saving vector registers on stack when passing variable arguments, the impacts of this option are callees may waste some stack space, misbehave or jump to a random location. GCC 4.4 or newer don’t have those issues, regardless the RAX register value. </p> </dd> <dt><code>-m8bit-idiv</code></dt> <dt><code>-mno-8bit-idiv</code></dt> <dd> <p id="index-m8bit-idiv">On some processors, like Intel Atom, 8-bit unsigned integer divide is much faster than 32-bit/64-bit integer divide. This option generates a run-time check. If both dividend and divisor are within range of 0 to 255, 8-bit unsigned integer divide is used instead of 32-bit/64-bit integer divide. </p> </dd> <dt><code>-mavx256-split-unaligned-load</code></dt> <dt><code>-mavx256-split-unaligned-store</code></dt> <dd>  <p id="index-mavx256-split-unaligned-store">Split 32-byte AVX unaligned load and store. </p> </dd> <dt><code>-mstack-protector-guard=<var>guard</var></code></dt> <dt><code>-mstack-protector-guard-reg=<var>reg</var></code></dt> <dt><code>-mstack-protector-guard-offset=<var>offset</var></code></dt> <dd>   <p id="index-mstack-protector-guard-offset-3">Generate stack protection code using canary at <var>guard</var>. Supported locations are ‘<samp>global</samp>’ for global canary or ‘<samp>tls</samp>’ for per-thread canary in the TLS block (the default). This option has effect only when <samp>-fstack-protector</samp> or <samp>-fstack-protector-all</samp> is specified. </p> <p>With the latter choice the options <samp>-mstack-protector-guard-reg=<var>reg</var></samp> and <samp>-mstack-protector-guard-offset=<var>offset</var></samp> furthermore specify which segment register (<code>%fs</code> or <code>%gs</code>) to use as base register for reading the canary, and from what offset from that base register. The default for those is as specified in the relevant ABI. </p> </dd> <dt><code>-mgeneral-regs-only</code></dt> <dd> <p id="index-mgeneral-regs-only-2">Generate code that uses only the general-purpose registers. This prevents the compiler from using floating-point, vector, mask and bound registers. </p> </dd> <dt><code>-mindirect-branch=<var>choice</var></code></dt> <dd> <p id="index-mindirect-branch">Convert indirect call and jump with <var>choice</var>. The default is ‘<samp>keep</samp>’, which keeps indirect call and jump unmodified. ‘<samp>thunk</samp>’ converts indirect call and jump to call and return thunk. ‘<samp>thunk-inline</samp>’ converts indirect call and jump to inlined call and return thunk. ‘<samp>thunk-extern</samp>’ converts indirect call and jump to external call and return thunk provided in a separate object file. You can control this behavior for a specific function by using the function attribute <code>indirect_branch</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> <p>Note that <samp>-mcmodel=large</samp> is incompatible with <samp>-mindirect-branch=thunk</samp> and <samp>-mindirect-branch=thunk-extern</samp> since the thunk function may not be reachable in the large code model. </p> <p>Note that <samp>-mindirect-branch=thunk-extern</samp> is compatible with <samp>-fcf-protection=branch</samp> since the external thunk can be made to enable control-flow check. </p> </dd> <dt><code>-mfunction-return=<var>choice</var></code></dt> <dd> <p id="index-mfunction-return">Convert function return with <var>choice</var>. The default is ‘<samp>keep</samp>’, which keeps function return unmodified. ‘<samp>thunk</samp>’ converts function return to call and return thunk. ‘<samp>thunk-inline</samp>’ converts function return to inlined call and return thunk. ‘<samp>thunk-extern</samp>’ converts function return to external call and return thunk provided in a separate object file. You can control this behavior for a specific function by using the function attribute <code>function_return</code>. See <a href="function-attributes#Function-Attributes">Function Attributes</a>. </p> <p>Note that <samp>-mindirect-return=thunk-extern</samp> is compatible with <samp>-fcf-protection=branch</samp> since the external thunk can be made to enable control-flow check. </p> <p>Note that <samp>-mcmodel=large</samp> is incompatible with <samp>-mfunction-return=thunk</samp> and <samp>-mfunction-return=thunk-extern</samp> since the thunk function may not be reachable in the large code model. </p> </dd> <dt><code>-mindirect-branch-register</code></dt> <dd> <p id="index-mindirect-branch-register">Force indirect call and jump via register. </p> </dd> </dl> <p>These ‘<samp>-m</samp>’ switches are supported in addition to the above on x86-64 processors in 64-bit environments. </p> <dl compact> <dt><code>-m32</code></dt> <dt><code>-m64</code></dt> <dt><code>-mx32</code></dt> <dt><code>-m16</code></dt> <dt><code>-miamcu</code></dt> <dd>     <p id="index-miamcu">Generate code for a 16-bit, 32-bit or 64-bit environment. The <samp>-m32</samp> option sets <code>int</code>, <code>long</code>, and pointer types to 32 bits, and generates code that runs on any i386 system. </p> <p>The <samp>-m64</samp> option sets <code>int</code> to 32 bits and <code>long</code> and pointer types to 64 bits, and generates code for the x86-64 architecture. For Darwin only the <samp>-m64</samp> option also turns off the <samp>-fno-pic</samp> and <samp>-mdynamic-no-pic</samp> options. </p> <p>The <samp>-mx32</samp> option sets <code>int</code>, <code>long</code>, and pointer types to 32 bits, and generates code for the x86-64 architecture. </p> <p>The <samp>-m16</samp> option is the same as <samp>-m32</samp>, except for that it outputs the <code>.code16gcc</code> assembly directive at the beginning of the assembly output so that the binary can run in 16-bit mode. </p> <p>The <samp>-miamcu</samp> option generates code which conforms to Intel MCU psABI. It requires the <samp>-m32</samp> option to be turned on. </p> </dd> <dt><code>-mno-red-zone</code></dt> <dd>  <p id="index-mred-zone">Do not use a so-called “red zone” for x86-64 code. The red zone is mandated by the x86-64 ABI; it is a 128-byte area beyond the location of the stack pointer that is not modified by signal or interrupt handlers and therefore can be used for temporary data without adjusting the stack pointer. The flag <samp>-mno-red-zone</samp> disables this red zone. </p> </dd> <dt><code>-mcmodel=small</code></dt> <dd> <p id="index-mcmodel_003dsmall-3">Generate code for the small code model: the program and its symbols must be linked in the lower 2 GB of the address space. Pointers are 64 bits. Programs can be statically or dynamically linked. This is the default code model. </p> </dd> <dt><code>-mcmodel=kernel</code></dt> <dd> <p id="index-mcmodel_003dkernel">Generate code for the kernel code model. The kernel runs in the negative 2 GB of the address space. This model has to be used for Linux kernel code. </p> </dd> <dt><code>-mcmodel=medium</code></dt> <dd> <p id="index-mcmodel_003dmedium-1">Generate code for the medium model: the program is linked in the lower 2 GB of the address space. Small symbols are also placed there. Symbols with sizes larger than <samp>-mlarge-data-threshold</samp> are put into large data or BSS sections and can be located above 2GB. Programs can be statically or dynamically linked. </p> </dd> <dt><code>-mcmodel=large</code></dt> <dd> <p id="index-mcmodel_003dlarge-3">Generate code for the large model. This model makes no assumptions about addresses and sizes of sections. </p> </dd> <dt><code>-maddress-mode=long</code></dt> <dd> <p id="index-maddress-mode_003dlong">Generate code for long address mode. This is only supported for 64-bit and x32 environments. It is the default address mode for 64-bit environments. </p> </dd> <dt><code>-maddress-mode=short</code></dt> <dd> <p id="index-maddress-mode_003dshort">Generate code for short address mode. This is only supported for 32-bit and x32 environments. It is the default address mode for 32-bit and x32 environments. </p>
</dd> </dl>  <p class="header"> <p> Next: <a href="x86-windows-options#x86-Windows-Options" accesskey="n" rel="next">x86 Windows Options</a>, Previous: <a href="vxworks-options#VxWorks-Options" accesskey="p" rel="prev">VxWorks Options</a>, Up: <a href="submodel-options#Submodel-Options" accesskey="u" rel="up">Submodel Options</a> [<a href="index#SEC_Contents" title="Table of contents" rel="contents">Contents</a>][<a href="https://gcc.gnu.org/onlinedocs/gcc-9.5.0/gcc/Option-Index.html#Option-Index" title="Index" rel="index">Index</a>]</p> </p><div class="_attribution">
  <p class="_attribution-p">
    &copy; Free Software Foundation<br>Licensed under the GNU Free Documentation License, Version 1.3.<br>
    <a href="https://gcc.gnu.org/onlinedocs/gcc-9.5.0/gcc/x86-Options.html" class="_attribution-link">https://gcc.gnu.org/onlinedocs/gcc-9.5.0/gcc/x86-Options.html</a>
  </p>
</div>
</div>
            </main>
        </div>
    </div>
    <script type="text/javascript" src="assets/index.js"></script>
</body>

</html>